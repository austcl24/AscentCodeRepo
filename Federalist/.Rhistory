plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S1 and S2, p: 0.0 to 0.9",
main = "Bayes Decision Rule with Odds of State S3 Fixed at 0.1",
ylab = "Expected Profit")
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 13/30, lty = 2)
(round(13/30,3))
text(x = 13/30, y = 192, sprintf("p = %.3f", 13/30), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
#12.2.6d
y1 <- c(164,209)
y2 <- c(177,195)
xval <- c(.0, .9)
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S1 and S2, p: 0.0 to 0.9",
main = "Bayes Decision Rule with Odds of State S3 Fixed at 0.1",
ylab = "Expected Profit")
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 13/30, lty = 2)
(round(13/30,3))
text(x = 13/30, y = 192, sprintf("p = %.3f", 13/30), adj = c(1.2, 0))
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S1 and S2, p: 0.0 to 0.9",
main = "Bayes Decision Rule with Odds of State S3 Fixed at 0.1",
ylab = "Expected Profit", ylim = c(160,215))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 13/30, lty = 2)
(round(13/30,3))
text(x = 13/30, y = 192, sprintf("p = %.3f", 13/30), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
#12.2.6e
y1 <- c(128,205)
y2 <- c(159,194)
xval <- c(.0, .7)
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S1 and S3, p: 0.0 to 0.7",
main = "Bayes Decision Rule with Odds of State S2 Fixed at 0.3",
ylab = "Expected Profit", ylim = c(120,215))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 31/60, lty = 2)
(round(31/60,3))
text(x = 31/60, y = 210, sprintf("p = %.3f", 31/60), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
#12.2.6f
y1 <- c(176,200)
y2 <- c(180,192)
xval <- c(.0, .4)
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S2 and S3, p: 0.0 to 0.4",
main = "Bayes Decision Rule with Odds of State S1 Fixed at 0.6",
ylab = "Expected Profit", ylim = c(170,210))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 4/30, lty = 2)
(round(4/3,3))
(round(4/30,3))
text(x = 4/30, y = 185, sprintf("p = %.3f", 4/3), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
text(x = 4/30, y = 185, sprintf("p = %.3f", 4/30), adj = c(1.2, 0))
#12.2.6f
y1 <- c(176,200)
y2 <- c(180,192)
xval <- c(.0, .4)
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S2 and S3, p: 0.0 to 0.4",
main = "Bayes Decision Rule with Odds of State S1 Fixed at 0.6",
ylab = "Expected Profit", ylim = c(170,210))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 4/30, lty = 2)
(round(4/30,3))
text(x = 4/30, y = 185, sprintf("p = %.3f", 4/30), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
# 12.2.6d
y1 <- c(164,209)
y2 <- c(177,195)
xval <- c(.0, .9)
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S1 and S2, p: 0.0 to 0.9",
main = "Bayes Decision Rule with Odds of State S3 Fixed at 0.1",
ylab = "Expected Profit", ylim = c(160,215))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 13/30, lty = 2)
(round(13/30,3))
text(x = 13/30, y = 192, sprintf("p = %.3f", 13/30), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
# 12.2.6e
y1 <- c(128,205)
y2 <- c(159,194)
xval <- c(.0, .7)
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S1 and S3, p: 0.0 to 0.7",
main = "Bayes Decision Rule with Odds of State S2 Fixed at 0.3",
ylab = "Expected Profit", ylim = c(120,215))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 31/60, lty = 2)
(round(31/60,3))
text(x = 31/60, y = 210, sprintf("p = %.3f", 31/60), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
# 12.2.6f
y1 <- c(176,200)
y2 <- c(180,192)
xval <- c(.0, .4)
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S2 and S3, p: 0.0 to 0.4",
main = "Bayes Decision Rule with Odds of State S1 Fixed at 0.6",
ylab = "Expected Profit", ylim = c(170,210))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 4/30, lty = 2)
text(x = 4/30, y = 185, sprintf("p = %.3f", 4/30), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
plot(x = xval, y=y2, type = "n", xlab = "Prior Probability (p) of states S2 and S3, p: 0.0 to 0.4",
main = "Bayes Decision Rule with Odds of State S1 Fixed at 0.6",
ylab = "Expected Profit", ylim = c(170,210))
points(x = xval, y = y1, pch = 20, type = "p", col = "red")
lines(x = xval, y = y1, pch = 20, col = "red")
points(x = xval, y = y2, pch = 20, type = "p", col = "blue")
lines(x = xval, y = y2, pch = 20, col = "blue")
abline(v = 4/30, lty = 2)
text(x = 4/30, y = 205, sprintf("p = %.3f", 4/30), adj = c(1.2, 0))
legend("bottomright", legend = c("Alternative 1", "Alternative 2"), title = "Alternatives",
pch = 20, col = c("red", "blue"))
vignette("details", package = "LDAvis")
install.packages("triangle")
?rlnorm
?rexp
?rweibull
require(triangle)
?rtriangle
lnProbs <- rlnorm(5000, .75.6)
lnProbs <- rlnorm(5000, .75, 6)
expProbs <- rexp(5000, 1.5)
weibProbs <- rweibull(5000, 2,3)
triProbs <- rtriangle(5000, 0, 1.2, 4)
triProbs <- rtriangle(5000, 0, 4, 1.2)
require(triangle)
set.seed(5)
lnProbs <- rlnorm(5000, .75, 6)
expProbs <- rexp(5000, 1.5)
weibProbs <- rweibull(5000, 2,3)
triProbs <- rtriangle(5000, 0, 4, 1.2)
lnProbs[1:5]
lnProbs[1:5]*1
lnProbs[1:5]*100
hourlyCosts <- c(70,80,130,90)
hourlyCost <- c(70,80,130,90)
partCost <- 200
rm(hourlyCosts)
?rep
laborSimCost <- rep(NA, 5000)
laborProbs <- c(.35, .4, .15, .10)
hourlyCost <- rep(c(70,80,130,90),1250)
laborProbs <- rep(c(.35, .4, .15, .10),1250)
i <- 1
hourlyCost <- c(70,80,130,90)
laborProbs <- c(.35, .4, .15, .10)
expectedCost[i] <-  lnProbs[i]*hourlyCost[1]*laborProbs[1]
expectedCost <- rep(NA, 5000)
rm(laborSimCost)
expectedCost[i] <-  lnProbs[i]*hourlyCost[1]*laborProbs[1]
expectedCost[i] <-  lnProbs[i]*hourlyCost[1]
expectedCost[i] <-  lnProbs[i]
expectedCost[i] <-  lnProbs[i]*hourlyCost[1]*laborProbs[1]+
expProbs[i]*hourlyCost[2]*laborProbs[2] +
weiProbs[i]*hourlyCost[3]*laborProbs[3] +
triProbs[i]*hourlyCost[4]*laborProbs[4] + PartCost
expectedCost[i] <-  lnProbs[i]*hourlyCost[1]*laborProbs[1]+
expProbs[i]*hourlyCost[2]*laborProbs[2] +
weibProbs[i]*hourlyCost[3]*laborProbs[3] +
triProbs[i]*hourlyCost[4]*laborProbs[4] + PartCost
partCost <- 200
expectedCost[i] <-  lnProbs[i]*hourlyCost[1]*laborProbs[1]+
expProbs[i]*hourlyCost[2]*laborProbs[2] +
weibProbs[i]*hourlyCost[3]*laborProbs[3] +
triProbs[i]*hourlyCost[4]*laborProbs[4] + PartCost
expectedCost[i] <-  lnProbs[i]*hourlyCost[1]*laborProbs[1]+
expProbs[i]*hourlyCost[2]*laborProbs[2] +
weibProbs[i]*hourlyCost[3]*laborProbs[3] +
triProbs[i]*hourlyCost[4]*laborProbs[4] + partCost
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
expectedCost[1:10]
sd(expectedCost)
?rlnorm
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
mean(expectedCost)
sd(expectedCost)
?rexp
?rweibull
print("Mean: %d, sd: %d", mean(expectedCost), sd(expectedCost))
sprintf("Mean: %d, sd: %d", mean(expectedCost), sd(expectedCost))
sprintf("Mean: %f, sd: %f", mean(expectedCost), sd(expectedCost))
sprintf("Mean: %f, sd: %f", round(mean(expectedCost),2), round(sd(expectedCost),2)
sprintf("Mean: %f, sd: %f", round(mean(expectedCost),2), round(sd(expectedCost),2)
)
sprintf("Mean: %f, sd: %f", round(mean(expectedCost),2), round(sd(expectedCost),2))
sprintf("Mean: %.2f, sd: %.2f", mean(expectedCost), sd(expectedCost))
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
head(expectedCost, 10)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
?rlnorm
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
source('D:/Coursework/DS775 - Prescriptive Analytics/Week 14/Final R Code.R', echo=TRUE)
?runif
runif(1)
runif(1)
a <- rep(200, 10000)
b <- runif(1, 10000)
b <- rep(runif(1), 10000)
b <- runif(10000)
b[b >.55] <- 0
c = a*b
rm(c)
b[b <= .55] <- 1
b <- runif(10000)
b[b >.55] <- 0
head(ceiling(b))
c = a*ceiling(b)
mean(c)
library("esquisse", lib.loc="~/R/win-library/3.5")
source('~/.active-rstudio-document', echo=TRUE)
library(devtools)
library(DS705data)
basedir <- "D:/Coursework/Summary/DS705_Revisited/"
data("HealthExam")
fs <- HealthExam[which(HealthExam$Sex == 'F'),10]
?t.test
?power.t.test
source('D:/Coursework/pnorm, dnorm, qnorm examples.R', echo=TRUE)
a <- rnorm(n = 500, mean = 17, sd = 6)
shapiro.test(a)
b <- rnorm(n = 300, mean = 15, sd = 3)
library(car)
leveneTest(a~b)
b <- rnorm(n = 500, mean = 15, sd = 3)
leveneTest(a~b)
?leveneTest
c = data.frame(a,b)
leveneTest(c)
c = data.frame(a,b, data = c)
c = data.frame(a,b)
leveneTest(a~b, data = c)
?rep
c(rep.int('A', 500), rep.int('B', 500)
)
c$colname <- c(rep.int('A', 500), rep.int('B', 500))
a <- data.frame(Column = "A", data = rnorm(n = 500, mean = 17, sd = 6))
b <- data.frame(Column = "B", data = rnorm(n = 500, mean = 14, sd = 4))
c <- rbind(a,b)
View(c)
leveneTest(data~column, data = c)
leveneTest(data~Column, data = c)
?leveneTest
options(blogdown.ext = ".Rmd", blogdown.author = "Chris Austin")
?options
options
options()
library("LDAvis", lib.loc="~/R/win-library/3.5")
# Text Analysis Final Project - Topic Modeling : The Federalist Papers
# DS 745 - Chris Austin
library(tm)           # 0.6-2
library(dplyr)        # 0.7.8
library(LDAvis)       # 0.3.2
library(SnowballC)    # 0.5.1
library(topicmodels)  # 0.2-7
#library(stringi)      # 1.2.4
library(stringr)      # 1.3.1
# Load in the Federalist data
con <- url("https://www.gutenberg.org/files/18/18.txt")
open(con, "r")
text.v <- readLines(con, n = -1, skipNul = TRUE)
close(con)
# Find out where paper 1 starts
start.v <- which(text.v == "FEDERALIST. No. 1")
end.v <- which(text.v == "End of the Project Gutenberg EBook of The Federalist Papers, by ")
# Remove leading and trailing data pertaining to Project Gutenberg
text.v <- text.v[c((start.v):(end.v-1))]
# Replace occurrences of double-hyphens with spaces. Otherwise some words parse poorly.
length(grep("--",text.v))
text.v <- str_replace_all(text.v, "--", " ")
# Determine starting positions of chapters
chap.positions.v <- grep("^FEDERALIST*", text.v)
# Two different versions of Federalist #70 are included in the Project Gutenberg
# file. Both are undisputed works of Alexander Hamiltion. We will remove the
# first one here.
start70a <- chap.positions.v[70]-1
end70a <- chap.positions.v[71]-1
text.v <- text.v[-c(start70a:end70a)]
chap.positions.v <- grep("^FEDERALIST*", text.v)
# Remove more metadata and re-gen chapter start locations
indJournal <- grep("*Independent Journal*", text.v)
dailyAdv <- grep("*Daily Advertiser*", text.v)
nyPacket <- grep("*New York Packet*", text.v)
mcLean <- grep("*M[cC]LEAN*", text.v)
text1787 <- grep("1787[.]", text.v)
toThePeople <- grep("To the People of the State of New York", text.v)
removeMeta <- c(indJournal, nyPacket, dailyAdv, mcLean, text1787, toThePeople)
text.v <- text.v[-c(removeMeta)]
chap.positions.v <- grep("^FEDERALIST*", text.v)
#Manipulate papers into one per row, first into a list then finally into a
#dataframe.
workList = list(NULL)
for(i in 1:length(chap.positions.v)) {
if(i < length(chap.positions.v)) {
workList[[i]] <- text.v[(chap.positions.v[i]+1):(chap.positions.v[i + 1]-1)]
}
else {
workList[[i]] <- text.v[(chap.positions.v[i]+1):length(text.v)]
}
}
workList2 = data.frame(Text = rep(NA, length(chap.positions.v)))
for(i in 1:length(chap.positions.v)) {
workList2[i,1] = as.vector(paste(unlist(workList[[i]]), collapse = " "))
}
workList2$Paper = sprintf("Fed %d", 1:85)
workList2$Author = c("Hamiltion", rep("Jay",4), rep("Hamilton",4), "Madison", rep("Hamilton",3),
"Madison", rep("Hamilton",3), rep("Madison",3), rep("Hamilton",16),
rep("Madison",12), rep("Disputed",10), rep("Hamilton",3), rep("Disputed",2),
"Jay", rep("Hamilton",21))
workList2$Label = sprintf("%s:%s",workList2$Paper, workList2$Author)
# Create a text corpus from the text for use in the statistical analysis
documents <- Corpus(VectorSource(workList2$Text))
documents <- tm_map(documents, removePunctuation)
documents <- tm_map(documents,content_transformer(tolower))
documents <- tm_map(documents, removeNumbers)
# The authors' names are in each paper. Those are removed, along with their
# common nom-de-plume, that of Roman general Publius.
documents <- tm_map(documents, removeWords, c(stopwords("english"), "jay", "hamilton", "madison", "publius"))
documents <- tm_map(documents, stripWhitespace)
# Stem the document for topic modeling
documents <- tm_map(documents, stemDocument)
# Example of cleaned text (one of the shorter papers)
documents[[13]]$content
dtMatrix <- DocumentTermMatrix(documents)
# dtMatrix excerpt and word frequencies
inspect(dtMatrix)
#matrixExcerpt <- inspect(dtMatrix)[,11:15]
#a <- matrixExcerpt[which(rowSums(matrixExcerpt) != 0),]
freq <- colSums(as.matrix(dtMatrix))
order <- order(freq, decreasing = TRUE)
#Set parameters for Gibbs sampling. changed nstart to 10 to increase number of
#runs.
burnin <- 1000
iter <- 1000
thin <- 100
nstart <- 10
seed <- rep(list(1),nstart)
best <- TRUE
#Number of topics - one pass with 3, and one pass with 4 to see if an
#additional topic is relevant. LDA() takes several minutes.
k3 <- 3
ldaOut3 <- LDA(dtMatrix,k3, method="Gibbs",
control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter))
#docs to topics
ldaOut.topics3 <- as.matrix(topics(ldaOut3))
#top 10 terms in each topic
ldaOut.terms3 <- as.matrix(terms(ldaOut3,10))
colnames(ldaOut.terms3) <- c("Topic 3.1", "Topic 3.2", "Topic 3.3")
# Overall topic counts for all 85 papers
rbind(ldaOut.terms3, c(rep("Paper Count",k3)), table(ldaOut.topics3))
#probabilities associated with each topic assignment
topicProbabilities3 <- as.data.frame(ldaOut3@gamma)
colnames(topicProbabilities3) <- c("pTopic1", "pTopic2", "pTopic3")
# Organize papers by topic
ldaOut.topics3.ID <- c("A Nation of Laws",
"Foreign Relations and External Conflict",
"Structure Amidst Differing Agendas")
sprintf("Topic 3.%d: %s",1:length(ldaOut.topics3.ID), ldaOut.topics3.ID)
(ldaOut.topics3.Set <- cbind(Paper = workList2$Label, round(topicProbabilities3,3), N = ldaOut.topics3,
TopicDesc = unname(apply(ldaOut.topics3, 1, FUN = function(x) (ldaOut.topics3.ID[x])))) )
# Five highest probabilities in topic 3.1
head(ldaOut.topics3.Set %>% arrange(desc(`pTopic1`)),5)
# Five highest probabilities in topic 3.2
head(ldaOut.topics3.Set %>% arrange(desc(`pTopic2`)),5)
# Five highest probabilities in topic 3.3
head(ldaOut.topics3.Set %>% arrange(desc(`pTopic3`)),5)
# Second run with k = 4
k4 <- 4
#Run LDA using Gibbs sampling, k = 4. LDA() takes several minutes.
ldaOut4 <- LDA(dtMatrix,k4, method="Gibbs",
control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter))
#docs to topics
ldaOut.topics4 <- as.matrix(topics(ldaOut4))
#top 10 terms in each topic
(ldaOut.terms4 <- as.matrix(terms(ldaOut4,10)))
colnames(ldaOut.terms4) <- c("Topic 4.1", "Topic 4.2", "Topic 4.3", "Topic 4.4")
# Overall topic counts for all 85 papers
rbind(ldaOut.terms4, c(rep("Paper Count",k4)), table(ldaOut.topics4))
#probabilities associated with each topic assignment
topicProbabilities4 <- as.data.frame(ldaOut4@gamma)
colnames(topicProbabilities4) <- c("pTopic1", "pTopic2", "pTopic3", "pTopic4")
# Organize papers by topic
ldaOut.topics4.ID <- c("Powers and Limitations of the Executive Branch",
"Structure Amidst Differing Agendas",
"A Nation of Laws",
"Internal/External Relations and Conflict")
sprintf("Topic 4.%d: %s",1:length(ldaOut.topics4.ID), ldaOut.topics4.ID)
(ldaOut.topics4.Set <- cbind(Paper = workList2$Label, round(topicProbabilities4,3), N = ldaOut.topics4,
TopicDesc = unname(apply(ldaOut.topics4, 1, FUN = function(x) (ldaOut.topics4.ID[x])))) )
# Five highest probabilities in topic 4.1
head(ldaOut.topics4.Set %>% arrange(desc(`pTopic1`)),5)
# Five highest probabilities in topic 4.2
head(ldaOut.topics4.Set %>% arrange(desc(`pTopic2`)),5)
# Five highest probabilities in topic 4.3
head(ldaOut.topics4.Set %>% arrange(desc(`pTopic3`)),5)
# Five highest probabilities in topic 4.4
head(ldaOut.topics4.Set %>% arrange(desc(`pTopic4`)),5)
# Function for visualization
topicmodels_json_ldavis <- function(fitted, corpus, doc_term){
# Find required quantities
phi <- posterior(fitted)$terms %>% as.matrix
theta <- posterior(fitted)$topics %>% as.matrix
vocab <- colnames(phi)
doc_length <- vector()
for (i in 1:length(corpus)) {
temp <- paste(corpus[[i]]$content, collapse = ' ')
# doc_length <- c(doc_length, stri_count(temp, regex = '\\S+'))
doc_length <- c(doc_length, str_count(temp, pattern = '\\S+'))
}
temp_frequency <- as.matrix(doc_term)
freq_matrix <- data.frame(ST = colnames(temp_frequency),
Freq = colSums(temp_frequency))
rm(temp_frequency)
# Convert to json
json_lda <- LDAvis::createJSON(phi = phi, theta=theta, vocab = vocab,
doc.length = doc_length,term.frequency = freq_matrix$Freq)
#freq_matrix$Freq
return(json_lda)
}
json1 <- topicmodels_json_ldavis(ldaOut4,documents,dtMatrix)
serVis(json1, out.dir = 'vis2', open.browser = TRUE)
documents$1
documents$1$content
documents$`1`
documents$`1`$content
documents$`1`$`content`
documents[1]
documents[[1]]
documents[[1]][["content"]]
documents[[1]] [["content"]]
documents[[1]] [["meta"]]
documents[[2]] [["content"]]
setwd("D:/liveblog/workfolder")
setwd("D:/liveblog/AscentCodeRepo/Federalist")
source('D:/liveblog/AscentCodeRepo/Federalist/LDA Blog post.R', echo=TRUE)
